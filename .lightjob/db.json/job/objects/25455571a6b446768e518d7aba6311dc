{"content": {"loss": 0.44989892648227564, "task": "regression", "dataset": "data/uci_standard/winequality-red.csv", "seed": 42, "params": {"minspan_alpha": 0.17007380976865097, "max_terms": 30.0, "enable_pruning": true, "endspan_alpha": 0.18642320467969226, "smooth": true, "max_degree": 41.0, "penalty": 3.7884758796429394, "thresh": 0.16964732276928934, "check_every": 55.0, "allow_missing": true, "allow_linear": true}, "result": {"status": "ok", "loss": 0.44989892648227564, "train_time": [0.16385102272033691, 0.14227294921875, 0.0965430736541748, 0.1298058032989502, 0.08303499221801758], "loss_variance": 0.0008857296615478802, "score_train": [0.4520969467656751, 0.428929418479593, 0.44511396212213084, 0.44624723976425784, 0.43805462007963564], "params": {"minspan_alpha": 0.17007380976865097, "max_terms": 30.0, "enable_pruning": true, "endspan_alpha": 0.18642320467969226, "smooth": true, "max_degree": 41.0, "penalty": 3.7884758796429394, "thresh": 0.16964732276928934, "check_every": 55.0, "allow_missing": true, "allow_linear": true}, "score_test": [0.40992533937196063, 0.49827083825354446, 0.44629563415737145, 0.43222988600042667, 0.46277293462807517]}, "model": "Earth"}, "life": [{"dt": "Fri Sep  2 12:00:59 2016", "state": "success"}], "state": "success", "summary": "b8e17f4d45d82025a8155d35cae60a79"}