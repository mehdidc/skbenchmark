{"content": {"loss": 0.44976365662489853, "task": "regression", "dataset": "data/uci_standard/winequality-red.csv", "seed": 42, "params": {"minspan_alpha": 0.2409176026338636, "max_terms": 45.0, "enable_pruning": true, "endspan_alpha": 0.8649536264017385, "smooth": true, "max_degree": 79.0, "penalty": 10.952094776474809, "thresh": 0.16556393814785056, "check_every": 93.0, "allow_missing": false, "allow_linear": true}, "result": {"status": "ok", "loss": 0.44976365662489853, "train_time": [0.05961203575134277, 0.06957697868347168, 0.08098101615905762, 0.41478705406188965, 0.03505992889404297], "loss_variance": 0.0009307738167173488, "score_train": [0.4534365384241071, 0.43158387240532453, 0.44511396212213084, 0.4483997148570085, 0.44326277383363594], "params": {"minspan_alpha": 0.2409176026338636, "max_terms": 45.0, "enable_pruning": true, "endspan_alpha": 0.8649536264017385, "smooth": true, "max_degree": 79.0, "penalty": 10.952094776474809, "thresh": 0.16556393814785056, "check_every": 93.0, "allow_missing": false, "allow_linear": true}, "score_test": [0.41109239128798614, 0.5029473184067369, 0.44629563415737145, 0.4329082405687116, 0.45557469870368694]}, "model": "Earth"}, "life": [{"dt": "Sun May 29 14:56:56 2016", "state": "success"}], "state": "success", "summary": "df4947a2243135febd3bc0cee5231faf"}