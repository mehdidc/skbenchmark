{"content": {"loss": 0.5900250633955613, "task": "regression", "dataset": "data/uci_standard/winequality-white.csv", "seed": 42, "params": {"minspan_alpha": 0.7702144061575261, "max_terms": 89.0, "enable_pruning": true, "endspan_alpha": 0.49332373300993104, "smooth": true, "max_degree": 56.0, "penalty": 10.97871322810465, "thresh": 0.14899250828754995, "check_every": 96.0, "allow_missing": true, "allow_linear": false}, "result": {"status": "ok", "loss": 0.5900250633955613, "train_time": [0.26505208015441895, 0.23786282539367676, 0.23116207122802734, 0.2539350986480713, 0.5890200138092041], "loss_variance": 0.004428670913401241, "score_train": [0.5605673200313268, 0.575751314900558, 0.582426428028672, 0.5871485105244617, 0.6120923717801329], "params": {"minspan_alpha": 0.7702144061575261, "max_terms": 89.0, "enable_pruning": true, "endspan_alpha": 0.49332373300993104, "smooth": true, "max_degree": 56.0, "penalty": 10.97871322810465, "thresh": 0.14899250828754995, "check_every": 96.0, "allow_missing": true, "allow_linear": false}, "score_test": [0.6846693595010251, 0.6186902476264807, 0.5934587946998616, 0.573131450408104, 0.48017546474233536]}, "model": "Earth"}, "life": [{"dt": "Sun May 29 14:58:39 2016", "state": "success"}], "state": "success", "summary": "101a7af863cfbca133f0b500cdb1baf8"}