{"content": {"loss": 0.6167858970557882, "task": "regression", "dataset": "data/uci_standard/winequality-white.csv", "seed": 42, "params": {"minspan_alpha": 0.12997074427285077, "max_terms": 89.0, "enable_pruning": false, "endspan_alpha": 0.6548897231099937, "smooth": false, "max_degree": 62.0, "penalty": 12.812090804814893, "thresh": 0.18937703072443526, "check_every": 66.0, "allow_missing": true, "allow_linear": false}, "result": {"status": "ok", "loss": 0.6167858970557882, "train_time": [0.5512750148773193, 0.11136722564697266, 0.12340807914733887, 0.11889481544494629, 0.2533590793609619], "loss_variance": 0.005359217832033943, "score_train": [0.5629192576989543, 0.6254605928280921, 0.6371345147705096, 0.6425612752148262, 0.6148554684019661], "params": {"minspan_alpha": 0.12997074427285077, "max_terms": 89.0, "enable_pruning": false, "endspan_alpha": 0.6548897231099937, "smooth": false, "max_degree": 62.0, "penalty": 12.812090804814893, "thresh": 0.18937703072443526, "check_every": 66.0, "allow_missing": true, "allow_linear": false}, "score_test": [0.688155543221765, 0.6758188329778445, 0.6301931912154047, 0.6069179618127875, 0.48284395605113933]}, "model": "Earth"}, "life": [{"dt": "Fri Sep  2 12:01:02 2016", "state": "success"}], "state": "success", "summary": "77dc3f46d67448319acda8d0495f9b5d"}