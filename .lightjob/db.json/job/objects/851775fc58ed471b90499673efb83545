{"content": {"loss": 0.44186866141244047, "task": "regression", "dataset": "data/uci_standard/winequality-red.csv", "seed": 42, "params": {"minspan_alpha": 0.7338479216645502, "max_terms": 62.0, "enable_pruning": true, "endspan_alpha": 0.8310083652912313, "smooth": true, "max_degree": 85.0, "penalty": 6.2921692546155334, "thresh": 0.0730354082270667, "check_every": 55.0, "allow_missing": false, "allow_linear": true}, "result": {"status": "ok", "loss": 0.44186866141244047, "train_time": [0.0943758487701416, 0.15589380264282227, 0.1217348575592041, 0.15505504608154297, 0.1553812026977539], "loss_variance": 0.00034180970918718906, "score_train": [0.4280453634942525, 0.41863514743341756, 0.4252397039338163, 0.4262187534977785, 0.4262263115083188], "params": {"minspan_alpha": 0.7338479216645502, "max_terms": 62.0, "enable_pruning": true, "endspan_alpha": 0.8310083652912313, "smooth": true, "max_degree": 85.0, "penalty": 6.2921692546155334, "thresh": 0.0730354082270667, "check_every": 55.0, "allow_missing": false, "allow_linear": true}, "score_test": [0.4598989380081272, 0.4660664175861699, 0.4367247660346353, 0.416832365076724, 0.42982082035654584]}, "model": "Earth"}, "life": [{"dt": "Sun May 29 14:56:59 2016", "state": "success"}], "state": "success", "summary": "5c678d3c470d3813a4a8ce6434dd70a7"}