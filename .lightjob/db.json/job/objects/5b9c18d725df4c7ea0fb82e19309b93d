{"content": {"loss": 0.44913226007081386, "task": "regression", "dataset": "data/uci_standard/winequality-red.csv", "seed": 42, "params": {"minspan_alpha": 0.08859587160294953, "max_terms": 35.0, "enable_pruning": true, "endspan_alpha": 0.04736070041969681, "smooth": true, "max_degree": 22.0, "penalty": 7.214446190435425, "thresh": 0.1118384179872992, "check_every": 51.0, "allow_missing": true, "allow_linear": true}, "result": {"status": "ok", "loss": 0.44913226007081386, "train_time": [0.395280122756958, 0.08697104454040527, 0.051219940185546875, 0.04165506362915039, 0.06317782402038574], "loss_variance": 0.000817633637603511, "score_train": [0.4534365384241071, 0.4311697451336315, 0.44511396212213084, 0.4483997148570085, 0.44089440323598666], "params": {"minspan_alpha": 0.08859587160294953, "max_terms": 35.0, "enable_pruning": true, "endspan_alpha": 0.04736070041969681, "smooth": true, "max_degree": 22.0, "penalty": 7.214446190435425, "thresh": 0.1118384179872992, "check_every": 51.0, "allow_missing": true, "allow_linear": true}, "score_test": [0.41109239128798614, 0.49691318219706204, 0.44629563415737145, 0.4329082405687116, 0.4584518521429382]}, "model": "Earth"}, "life": [{"dt": "Fri Sep  2 12:00:59 2016", "state": "success"}], "state": "success", "summary": "d14c6c8d562dca26be4f73d31ee96ac9"}