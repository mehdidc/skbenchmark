{"content": {"loss": 0.6392072953542816, "task": "regression", "dataset": "data/uci_standard/winequality-white.csv", "seed": 42, "params": {"minspan_alpha": 0.08513602046127866, "max_terms": 64.0, "enable_pruning": true, "endspan_alpha": 0.08528191166446719, "smooth": true, "max_degree": 15.0, "penalty": 4.242544869151573, "thresh": 0.4608910958350093, "check_every": 88.0, "allow_missing": false, "allow_linear": false}, "result": {"status": "ok", "loss": 0.6392072953542816, "train_time": [0.16242313385009766, 0.17307591438293457, 0.2669641971588135, 0.21937894821166992, 0.15883183479309082], "loss_variance": 0.003913188923039752, "score_train": [0.6097507712179241, 0.6241487634054295, 0.6359068083815824, 0.6414415949281495, 0.6570808718921941], "params": {"minspan_alpha": 0.08513602046127866, "max_terms": 64.0, "enable_pruning": true, "endspan_alpha": 0.08528191166446719, "smooth": true, "max_degree": 15.0, "penalty": 4.242544869151573, "thresh": 0.4608910958350093, "check_every": 88.0, "allow_missing": false, "allow_linear": false}, "score_test": [0.735431763635929, 0.6750875761949823, 0.6291448551688658, 0.6053061194817834, 0.5510661622898473]}, "model": "Earth"}, "life": [{"dt": "Fri Sep  2 12:01:01 2016", "state": "success"}], "state": "success", "summary": "d52be5c9e53ab0145fc03ba292fa194c"}