{"content": {"loss": 0.4426255613521678, "task": "regression", "dataset": "data/uci_standard/winequality-red.csv", "seed": 42, "params": {"minspan_alpha": 0.37806876750488516, "max_terms": 32.0, "enable_pruning": true, "endspan_alpha": 0.7082162493570252, "smooth": true, "max_degree": 66.0, "penalty": 17.223954104258933, "thresh": 0.03820303954608363, "check_every": 94.0, "allow_missing": false, "allow_linear": true}, "result": {"status": "ok", "loss": 0.4426255613521678, "train_time": [0.07802104949951172, 0.08572196960449219, 0.08187103271484375, 0.08071613311767578, 0.08315014839172363], "loss_variance": 0.0004006951718255454, "score_train": [0.4280453634942525, 0.42199145225446016, 0.4293246410424083, 0.4350991603555976, 0.4324062606922657], "params": {"minspan_alpha": 0.37806876750488516, "max_terms": 32.0, "enable_pruning": true, "endspan_alpha": 0.7082162493570252, "smooth": true, "max_degree": 66.0, "penalty": 17.223954104258933, "thresh": 0.03820303954608363, "check_every": 94.0, "allow_missing": false, "allow_linear": true}, "score_test": [0.4598989380081272, 0.4707335400802425, 0.437697222128924, 0.4163767586883417, 0.42842134785520375]}, "model": "Earth"}, "life": [{"dt": "Sun May 29 14:56:53 2016", "state": "success"}], "state": "success", "summary": "fd59224d801e851c17e2dbdbcc132d66"}