{"content": {"loss": 0.5885457171163899, "task": "regression", "dataset": "data/uci_standard/winequality-white.csv", "seed": 42, "params": {"minspan_alpha": 0.8128481036822881, "max_terms": 48.0, "enable_pruning": false, "endspan_alpha": 0.67022885889418, "smooth": true, "max_degree": 78.0, "penalty": 12.334304866315712, "thresh": 0.1594778020693987, "check_every": 73.0, "allow_missing": false, "allow_linear": false}, "result": {"status": "ok", "loss": 0.5885457171163899, "train_time": [0.31450700759887695, 0.28038692474365234, 0.2706880569458008, 0.24991202354431152, 0.2808370590209961], "loss_variance": 0.004402242763902275, "score_train": [0.5585766410576068, 0.5729370451959777, 0.5799443320483304, 0.5849569711919287, 0.6098089643678961], "params": {"minspan_alpha": 0.8128481036822881, "max_terms": 48.0, "enable_pruning": false, "endspan_alpha": 0.67022885889418, "smooth": true, "max_degree": 78.0, "penalty": 12.334304866315712, "thresh": 0.1594778020693987, "check_every": 73.0, "allow_missing": false, "allow_linear": false}, "score_test": [0.6810375589580946, 0.6192053467698562, 0.5924358961388659, 0.5720968375673089, 0.477952946147824]}, "model": "Earth"}, "life": [{"dt": "Fri Sep  2 12:01:02 2016", "state": "success"}], "state": "success", "summary": "7ef9d23242c049312274679bf5c15e4b"}