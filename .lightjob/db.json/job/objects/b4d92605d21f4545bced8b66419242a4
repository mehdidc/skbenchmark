{"content": {"loss": 0.6391618282354946, "task": "regression", "dataset": "data/uci_standard/winequality-white.csv", "seed": 42, "params": {"minspan_alpha": 0.7183077773593277, "max_terms": 28.0, "enable_pruning": true, "endspan_alpha": 0.7430509679888939, "smooth": true, "max_degree": 55.0, "penalty": 12.460390869937187, "thresh": 0.8114036263085849, "check_every": 67.0, "allow_missing": true, "allow_linear": false}, "result": {"status": "ok", "loss": 0.6391618282354946, "train_time": [0.1718730926513672, 0.15626215934753418, 0.15939593315124512, 0.1554558277130127, 0.18662285804748535], "loss_variance": 0.003924015834210904, "score_train": [0.6097429556783827, 0.6240783790959035, 0.6358660887727289, 0.6414221260664869, 0.657075407846308], "params": {"minspan_alpha": 0.7183077773593277, "max_terms": 28.0, "enable_pruning": true, "endspan_alpha": 0.7430509679888939, "smooth": true, "max_degree": 55.0, "penalty": 12.460390869937187, "thresh": 0.8114036263085849, "check_every": 67.0, "allow_missing": true, "allow_linear": false}, "score_test": [0.7353715729118302, 0.6752773795684677, 0.6292303904988821, 0.6050819548512879, 0.5508478433470045]}, "model": "Earth"}, "life": [{"dt": "Sun May 29 14:58:31 2016", "state": "success"}], "state": "success", "summary": "4007ca8f81dbe3b5e29fd19060de72ef"}