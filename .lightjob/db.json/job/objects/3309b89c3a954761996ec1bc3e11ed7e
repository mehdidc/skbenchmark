{"content": {"loss": 0.640328250443417, "task": "regression", "dataset": "data/uci_standard/winequality-white.csv", "seed": 42, "params": {"minspan_alpha": 0.27736819222220344, "max_terms": 21.0, "enable_pruning": true, "endspan_alpha": 0.1625076057136432, "smooth": false, "max_degree": 52.0, "penalty": 13.626155272673616, "thresh": 0.48077152690834307, "check_every": 49.0, "allow_missing": true, "allow_linear": false}, "result": {"status": "ok", "loss": 0.640328250443417, "train_time": [0.1563560962677002, 0.12510895729064941, 0.1253519058227539, 0.1291639804840088, 0.07091498374938965], "loss_variance": 0.0039077668976931716, "score_train": [0.6109662796522857, 0.6254860113908879, 0.6371464921974379, 0.642551292537453, 0.658252418739393], "params": {"minspan_alpha": 0.27736819222220344, "max_terms": 21.0, "enable_pruning": true, "endspan_alpha": 0.1625076057136432, "smooth": false, "max_degree": 52.0, "penalty": 13.626155272673616, "thresh": 0.48077152690834307, "check_every": 49.0, "allow_missing": true, "allow_linear": false}, "score_test": [0.7366659979853816, 0.6757789520780915, 0.6301531312578438, 0.6069322273084578, 0.5521109435873103]}, "model": "Earth"}, "life": [{"dt": "Sun May 29 14:58:45 2016", "state": "success"}], "state": "success", "summary": "b419986a50c05195e0bd76a31b4a1176"}