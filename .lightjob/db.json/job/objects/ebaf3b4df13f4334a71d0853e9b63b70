{"content": {"loss": 0.5998055340643554, "task": "regression", "dataset": "data/uci_standard/winequality-white.csv", "seed": 42, "params": {"minspan_alpha": 0.36230723989290003, "max_terms": 12.0, "enable_pruning": true, "endspan_alpha": 0.240626589472663, "smooth": false, "max_degree": 64.0, "penalty": 6.904456630490831, "thresh": 0.048706296029576726, "check_every": 14.0, "allow_missing": false, "allow_linear": true}, "result": {"status": "ok", "loss": 0.5998055340643554, "train_time": [0.20565485954284668, 0.1367509365081787, 0.2569708824157715, 0.2609279155731201, 0.2773559093475342], "loss_variance": 0.005664430267610856, "score_train": [0.5482812920969351, 0.588633425428642, 0.5774664663011337, 0.5802941630074192, 0.6216488071039734], "params": {"minspan_alpha": 0.36230723989290003, "max_terms": 12.0, "enable_pruning": true, "endspan_alpha": 0.240626589472663, "smooth": false, "max_degree": 64.0, "penalty": 6.904456630490831, "thresh": 0.048706296029576726, "check_every": 14.0, "allow_missing": false, "allow_linear": true}, "score_test": [0.7260325985514433, 0.6251884940141295, 0.5845368720836253, 0.5649287657659534, 0.49834093990662576]}, "model": "Earth"}, "life": [{"dt": "Sun May 29 14:58:49 2016", "state": "success"}], "state": "success", "summary": "2b729102f9522b1e02d905f9859f42fd"}