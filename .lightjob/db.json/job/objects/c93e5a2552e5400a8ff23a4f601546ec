{"content": {"loss": 0.6389684636599055, "task": "regression", "dataset": "data/uci_standard/winequality-white.csv", "seed": 42, "params": {"minspan_alpha": 0.004350796492622433, "max_terms": 57.0, "enable_pruning": false, "endspan_alpha": 0.39656082323182046, "smooth": true, "max_degree": 86.0, "penalty": 15.349462868439158, "thresh": 0.9969227228267694, "check_every": 78.0, "allow_missing": false, "allow_linear": false}, "result": {"status": "ok", "loss": 0.6389684636599055, "train_time": [0.09539389610290527, 0.12700295448303223, 0.12973809242248535, 0.09674596786499023, 0.13040995597839355], "loss_variance": 0.003926832542678687, "score_train": [0.6093003387868778, 0.6233203162386237, 0.6352828360000389, 0.6408501545300479, 0.6565931404719335], "params": {"minspan_alpha": 0.004350796492622433, "max_terms": 57.0, "enable_pruning": false, "endspan_alpha": 0.39656082323182046, "smooth": true, "max_degree": 86.0, "penalty": 15.349462868439158, "thresh": 0.9969227228267694, "check_every": 78.0, "allow_missing": false, "allow_linear": false}, "score_test": [0.7345684980943882, 0.6759602731623691, 0.6291542842632492, 0.6049009288245348, 0.5502583339549859]}, "model": "Earth"}, "life": [{"dt": "Fri Sep  2 12:01:02 2016", "state": "success"}], "state": "success", "summary": "8bbdec470fcf0907d0db01ae9c4d3c3b"}