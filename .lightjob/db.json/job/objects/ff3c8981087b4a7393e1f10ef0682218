{"content": {"loss": 0.511006728552512, "task": "regression", "dataset": "data/uci_standard/winequality-red.csv", "seed": 42, "params": {"minspan_alpha": 0.07816987637678505, "max_terms": 83.0, "enable_pruning": true, "endspan_alpha": 0.753747475149964, "smooth": true, "max_degree": 100.0, "penalty": 17.025023978315133, "thresh": 0.4548180128378291, "check_every": 66.0, "allow_missing": true, "allow_linear": true}, "result": {"status": "ok", "loss": 0.511006728552512, "train_time": [0.0310819149017334, 0.03564810752868652, 0.032102108001708984, 0.03015303611755371, 0.029309988021850586], "loss_variance": 0.000709909347352826, "score_train": [0.5123177844414424, 0.49832870758201725, 0.5035620973734329, 0.5066297865569409, 0.4952375897145041], "params": {"minspan_alpha": 0.07816987637678505, "max_terms": 83.0, "enable_pruning": true, "endspan_alpha": 0.753747475149964, "smooth": true, "max_degree": 100.0, "penalty": 17.025023978315133, "thresh": 0.4548180128378291, "check_every": 66.0, "allow_missing": true, "allow_linear": true}, "score_test": [0.4712710130119772, 0.5329345675999599, 0.507852027348376, 0.4963869960034625, 0.5465890387987837]}, "model": "Earth"}, "life": [{"dt": "Sun May 29 14:56:49 2016", "state": "success"}], "state": "success", "summary": "e920cc1f1f935bcbe0b48f2063206c9f"}