{"content": {"loss": 0.4366136655559981, "task": "regression", "dataset": "data/uci_standard/winequality-red.csv", "seed": 42, "params": {"minspan_alpha": 0.082932850434071, "max_terms": 94.0, "enable_pruning": true, "endspan_alpha": 0.8859746138661754, "smooth": true, "max_degree": 78.0, "penalty": 4.465720619005191, "thresh": 0.08816332598746142, "check_every": 99.0, "allow_missing": false, "allow_linear": true}, "result": {"status": "ok", "loss": 0.4366136655559981, "train_time": [0.46265292167663574, 0.15343689918518066, 0.1100931167602539, 0.14947104454040527, 0.07300806045532227], "loss_variance": 0.00045700942487889517, "score_train": [0.4520969467656751, 0.41568596270410857, 0.4206885954685686, 0.4262187534977785, 0.4407178525860259], "params": {"minspan_alpha": 0.082932850434071, "max_terms": 94.0, "enable_pruning": true, "endspan_alpha": 0.8859746138661754, "smooth": true, "max_degree": 78.0, "penalty": 4.465720619005191, "thresh": 0.08816332598746142, "check_every": 99.0, "allow_missing": false, "allow_linear": true}, "score_test": [0.40992533937196063, 0.4616828108649381, 0.43458543080174666, 0.416832365076724, 0.46004238166462136]}, "model": "Earth"}, "life": [{"dt": "Sun May 29 14:56:47 2016", "state": "success"}], "state": "success", "summary": "681724497fce49b35fa4748bb69f8680"}