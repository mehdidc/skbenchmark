{"content": {"loss": 0.6402893584233078, "task": "regression", "dataset": "data/uci_standard/winequality-white.csv", "seed": 42, "params": {"minspan_alpha": 0.1789905858842149, "max_terms": 47.0, "enable_pruning": true, "endspan_alpha": 0.673965531883533, "smooth": false, "max_degree": 39.0, "penalty": 1.0761242133123528, "thresh": 0.9728258707297891, "check_every": 1.0, "allow_missing": true, "allow_linear": true}, "result": {"status": "ok", "loss": 0.6402893584233078, "train_time": [0.15222907066345215, 0.11806797981262207, 0.1121828556060791, 0.07702398300170898, 0.15355300903320312], "loss_variance": 0.003915299115219768, "score_train": [0.6109409113716506, 0.6254623678697293, 0.6371368617154263, 0.6425765483786429, 0.6582700523056485], "params": {"minspan_alpha": 0.1789905858842149, "max_terms": 47.0, "enable_pruning": true, "endspan_alpha": 0.673965531883533, "smooth": false, "max_degree": 39.0, "penalty": 1.0761242133123528, "thresh": 0.9728258707297891, "check_every": 1.0, "allow_missing": true, "allow_linear": true}, "score_test": [0.7366981841121334, 0.6758061244686719, 0.6301742328299963, 0.6067627907566271, 0.5520054599491105]}, "model": "Earth"}, "life": [{"dt": "Fri Sep  2 12:01:01 2016", "state": "success"}], "state": "success", "summary": "7902f62e16d7733da68f892a34f6f12d"}