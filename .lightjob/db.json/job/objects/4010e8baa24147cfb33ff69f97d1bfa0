{"content": {"loss": 0.442103066560949, "task": "regression", "dataset": "data/uci_standard/winequality-red.csv", "seed": 42, "params": {"minspan_alpha": 0.2680065107488931, "max_terms": 34.0, "enable_pruning": true, "endspan_alpha": 0.7106443637934048, "smooth": true, "max_degree": 73.0, "penalty": 6.819808047839061, "thresh": 0.0586865492204872, "check_every": 91.0, "allow_missing": false, "allow_linear": true}, "result": {"status": "ok", "loss": 0.442103066560949, "train_time": [0.09108495712280273, 0.1410200595855713, 0.10166192054748535, 0.1582050323486328, 0.14015603065490723], "loss_variance": 0.00033195663721708043, "score_train": [0.4280453634942525, 0.4217601676160302, 0.4252397039338163, 0.4294797763847647, 0.4294740193164575], "params": {"minspan_alpha": 0.2680065107488931, "max_terms": 34.0, "enable_pruning": true, "endspan_alpha": 0.7106443637934048, "smooth": true, "max_degree": 73.0, "penalty": 6.819808047839061, "thresh": 0.0586865492204872, "check_every": 91.0, "allow_missing": false, "allow_linear": true}, "score_test": [0.4598989380081272, 0.46529741350148424, 0.4367247660346353, 0.41586852672691477, 0.43272568853358345]}, "model": "Earth"}, "life": [{"dt": "Sun May 29 14:56:50 2016", "state": "success"}], "state": "success", "summary": "bcc800566ac39e397917e64cb64310c5"}