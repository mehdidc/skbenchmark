{"content": {"loss": 0.4339667295998658, "task": "regression", "dataset": "data/uci_standard/winequality-red.csv", "seed": 42, "params": {"minspan_alpha": 0.032534954910752464, "max_terms": 42.0, "enable_pruning": true, "endspan_alpha": 0.2708375140353687, "smooth": true, "max_degree": 48.0, "penalty": 6.266443398545631, "thresh": 0.029743706585377956, "check_every": 50.0, "allow_missing": true, "allow_linear": true}, "result": {"status": "ok", "loss": 0.4339667295998658, "train_time": [0.2130880355834961, 0.6494481563568115, 0.28827905654907227, 0.28124499320983887, 0.23631000518798828], "loss_variance": 0.00035823035545497, "score_train": [0.41828427452647515, 0.41679787233034526, 0.41049261726128233, 0.4181775353921279, 0.42021885642080725], "params": {"minspan_alpha": 0.032534954910752464, "max_terms": 42.0, "enable_pruning": true, "endspan_alpha": 0.2708375140353687, "smooth": true, "max_degree": 48.0, "penalty": 6.266443398545631, "thresh": 0.029743706585377956, "check_every": 50.0, "allow_missing": true, "allow_linear": true}, "score_test": [0.4413373046888144, 0.4628508877806973, 0.43252632664920665, 0.40442617563352457, 0.4286929532470859]}, "model": "Earth"}, "life": [{"dt": "Fri Sep  2 12:00:59 2016", "state": "success"}], "state": "success", "summary": "80dbabe2417c5ab9c0a53fd81de96f9f"}