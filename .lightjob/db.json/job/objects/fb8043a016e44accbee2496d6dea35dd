{"content": {"loss": 0.510936523485206, "task": "regression", "dataset": "data/uci_standard/winequality-red.csv", "seed": 42, "params": {"minspan_alpha": 0.16904466665651752, "max_terms": 87.0, "enable_pruning": true, "endspan_alpha": 0.9619317025634411, "smooth": true, "max_degree": 44.0, "penalty": 0.4160796918841969, "thresh": 0.26323761284507696, "check_every": 30.0, "allow_missing": true, "allow_linear": true}, "result": {"status": "ok", "loss": 0.510936523485206, "train_time": [0.06062006950378418, 0.08385896682739258, 0.05153083801269531, 0.06446194648742676, 0.05986785888671875], "loss_variance": 0.0008788075677466896, "score_train": [0.5089257096492437, 0.4932980978168282, 0.5035620973734329, 0.5018700077349696, 0.4924329245798161], "params": {"minspan_alpha": 0.16904466665651752, "max_terms": 87.0, "enable_pruning": true, "endspan_alpha": 0.9619317025634411, "smooth": true, "max_degree": 44.0, "penalty": 0.4160796918841969, "thresh": 0.26323761284507696, "check_every": 30.0, "allow_missing": true, "allow_linear": true}, "score_test": [0.4659856183069939, 0.5347083480181551, 0.507852027348376, 0.4956413212901607, 0.5504953024623442]}, "model": "Earth"}, "life": [{"dt": "Fri Sep  2 12:00:59 2016", "state": "success"}], "state": "success", "summary": "ee61166ff31a632401b49054dcd9d08b"}