{"content": {"loss": 0.44203704966120905, "task": "regression", "dataset": "data/uci_standard/winequality-red.csv", "seed": 42, "params": {"minspan_alpha": 0.5832440813227532, "max_terms": 24.0, "enable_pruning": true, "endspan_alpha": 0.9206066463024697, "smooth": true, "max_degree": 90.0, "penalty": 7.891034933343717, "thresh": 0.07056770262252218, "check_every": 74.0, "allow_missing": false, "allow_linear": true}, "result": {"status": "ok", "loss": 0.44203704966120905, "train_time": [0.08078503608703613, 0.13715410232543945, 0.09475302696228027, 0.4035181999206543, 0.14554095268249512], "loss_variance": 0.00033543791611317876, "score_train": [0.4280453634942525, 0.4217601676160302, 0.4252397039338163, 0.43313005914992503, 0.4294740193164575], "params": {"minspan_alpha": 0.5832440813227532, "max_terms": 24.0, "enable_pruning": true, "endspan_alpha": 0.9206066463024697, "smooth": true, "max_degree": 90.0, "penalty": 7.891034933343717, "thresh": 0.07056770262252218, "check_every": 74.0, "allow_missing": false, "allow_linear": true}, "score_test": [0.4598989380081272, 0.46529741350148424, 0.4367247660346353, 0.4155384422282151, 0.43272568853358345]}, "model": "Earth"}, "life": [{"dt": "Sun May 29 14:56:54 2016", "state": "success"}], "state": "success", "summary": "4dea88bb2dbcf4391290f806b58bcf5b"}