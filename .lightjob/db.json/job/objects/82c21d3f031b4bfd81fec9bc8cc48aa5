{"content": {"loss": 0.6389188658908426, "task": "regression", "dataset": "data/uci_standard/winequality-white.csv", "seed": 42, "params": {"minspan_alpha": 0.5337041335079029, "max_terms": 49.0, "enable_pruning": false, "endspan_alpha": 0.6732068268837565, "smooth": true, "max_degree": 56.0, "penalty": 6.6110181243933415, "thresh": 0.21450388071579604, "check_every": 64.0, "allow_missing": false, "allow_linear": false}, "result": {"status": "ok", "loss": 0.6389188658908426, "train_time": [0.1744379997253418, 0.3665890693664551, 0.09930205345153809, 0.12650299072265625, 0.12183022499084473], "loss_variance": 0.003935642031486768, "score_train": [0.6093003387868778, 0.6233203162386237, 0.6352828360000389, 0.6408501545300479, 0.6567055656193032], "params": {"minspan_alpha": 0.5337041335079029, "max_terms": 49.0, "enable_pruning": false, "endspan_alpha": 0.6732068268837565, "smooth": true, "max_degree": 56.0, "penalty": 6.6110181243933415, "thresh": 0.21450388071579604, "check_every": 64.0, "allow_missing": false, "allow_linear": false}, "score_test": [0.7345684980943882, 0.6759602731623691, 0.6291542842632492, 0.6049009288245348, 0.5500103451096712]}, "model": "Earth"}, "life": [{"dt": "Fri Sep  2 12:01:02 2016", "state": "success"}], "state": "success", "summary": "0cd40c3a5646cdbc6445658fa9bf940e"}