{"content": {"loss": 0.5112278042304468, "task": "regression", "dataset": "data/uci_standard/winequality-red.csv", "seed": 42, "params": {"minspan_alpha": 0.35829647481657634, "max_terms": 74.0, "enable_pruning": true, "endspan_alpha": 0.9484711463949946, "smooth": true, "max_degree": 52.0, "penalty": 8.890238682997904, "thresh": 0.404961222772569, "check_every": 87.0, "allow_missing": true, "allow_linear": true}, "result": {"status": "ok", "loss": 0.5112278042304468, "train_time": [0.03012704849243164, 0.028289079666137695, 0.030874013900756836, 0.027517080307006836, 0.037164926528930664], "loss_variance": 0.0007258376118946892, "score_train": [0.5123177844414424, 0.49832870758201725, 0.5035620973734329, 0.5066297865569409, 0.49381321520534877], "params": {"minspan_alpha": 0.35829647481657634, "max_terms": 74.0, "enable_pruning": true, "endspan_alpha": 0.9484711463949946, "smooth": true, "max_degree": 52.0, "penalty": 8.890238682997904, "thresh": 0.404961222772569, "check_every": 87.0, "allow_missing": true, "allow_linear": true}, "score_test": [0.4712710130119772, 0.5329345675999599, 0.507852027348376, 0.4963869960034625, 0.547694417188458]}, "model": "Earth"}, "life": [{"dt": "Sun May 29 14:56:48 2016", "state": "success"}], "state": "success", "summary": "774b314892984a0702990fb1ceb18a24"}