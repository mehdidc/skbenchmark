{"content": {"loss": 0.5106110342295926, "task": "regression", "dataset": "data/uci_standard/winequality-red.csv", "seed": 42, "params": {"minspan_alpha": 0.6908848550268617, "max_terms": 75.0, "enable_pruning": false, "endspan_alpha": 0.7800277619120791, "smooth": true, "max_degree": 54.0, "penalty": 8.569418523736514, "thresh": 0.6964691855978616, "check_every": 69.0, "allow_missing": true, "allow_linear": false}, "result": {"status": "ok", "loss": 0.5106110342295926, "train_time": [0.13481712341308594, 0.29531002044677734, 0.06104302406311035, 0.12618207931518555, 0.08447098731994629], "loss_variance": 0.0008812392814718066, "score_train": [0.5089257096492437, 0.4932980978168282, 0.50355256835128, 0.5018700077349696, 0.4924329245798161], "params": {"minspan_alpha": 0.6908848550268617, "max_terms": 75.0, "enable_pruning": false, "endspan_alpha": 0.7800277619120791, "smooth": true, "max_degree": 54.0, "penalty": 8.569418523736514, "thresh": 0.6964691855978616, "check_every": 69.0, "allow_missing": true, "allow_linear": false}, "score_test": [0.4659856183069939, 0.5347083480181551, 0.5062245810703092, 0.4956413212901607, 0.5504953024623442]}, "model": "Earth"}, "life": [{"dt": "Sun May 29 14:56:41 2016", "state": "success"}], "state": "success", "summary": "c684ced310afb9a6af2ff9e2a01c8a09"}